### 해석본
### 0. Abstract
보기에 따라 달라지는 효과를 지원하는 옥트리 기반 3D 표현인 PlenOctrees를 사용하여 신경 방사 필드(NeRF)를 실시간으로 렌더링하는 방법을 소개합니다. 이 방식은 800×800 이미지를 150FPS 이상으로 렌더링할 수 있으며, 이는 기존 NeRF보다 3000배 이상 빠른 속도입니다. 또한 임의의 지오메트리와 뷰 종속 효과가 있는 장면의 자유 시점 렌더링을 수행하는 NeRF의 기능을 유지하면서 품질 저하 없이 렌더링할 수 있습니다. 실시간 성능은 NeRF를 플렌옥트리에 사전 테이블링하여 달성합니다. 스페큘러와 같은 뷰 의존적 효과를 보존하기 위해 폐쇄형 구형 기저 함수를 통해 광도를 인수분해합니다. 특히, 우리는 신경망의 입력으로 보는 방향을 다시 이동하여 광도의 구형 고조파 표현을 미리 지시하도록 NeRF를 훈련할 수 있음을 보여줍니다. 또한 재구성 손실을 최소화하기 위해 플렌옥트리를 직접적으로 최적화할 수 있으며, 이를 통해 컴펫팅 방식과 비교했을 때 동등하거나 더 나은 품질을 얻을 수 있음을 보여줍니다. 또한 이 옥트리 최적화 단계는 NeRF 훈련이 완전히 수렴될 때까지 기다릴 필요가 없기 때문에 훈련 시간을 단축하는 데 사용할 수 있습니다. 저희의 실시간 뉴럴 렌더링 접근 방식은 6-DOF 산업 및 제품 시각화, 차세대 AR/VR 시스템과 같은 새로운 애플리케이션을 구현할 수 있습니다. 플렌옥트리는 브라우저 내 렌더링도 가능하며, 프로젝트 페이지에서 인터랙티브 온라인 데모와 동영상 및 코드를 확인할 수 있습니다(https://alexyu.net/plenoctrees).

### 1. Introduction
실시간 그래픽의 발전에도 불구하고, 최적화된 3D 에셋과 전용 셰이더의 부재로 인해 사실적인 장면과 오브젝트가 포함된 인터랙티브 3D 콘텐츠는 여전히 제작에 많은 시간과 비용이 소요됩니다. 그 대신 많은 그래픽 애플리케이션이 이미지 기반 솔루션을 선택합니다. 이커머스 웹사이트는 제품을 보여주기 위해 고정된 뷰 세트를 사용하는 경우가 많고, VR 경험은 실제 3D 장면을 제작하는 데 비용이 많이 드는 것을 피하기 위해 360도 비디오 녹화에 의존하며, Google 스트리트 뷰와 같은 매핑 서비스는 이미지를 3DOF로 제한된 파노라마 뷰로 합성합니다.
최근 신경 볼륨[24] 및 신경 방사장(NeRF)[30]과 같은 신경 렌더링의 발전으로 보정된 이미지 세트에서 임의의 물체와 장면을 3D로 모델링할 수 있는 새로운 길이 열렸습니다. 특히 NeRF는 어떤 관점에서든 비램버트 효과가 적용된 세부적인 장면과 외관을 충실하게 렌더링할 수 있으며, 동시에 스토리지 측면에서 높은 수준의 압축을 제공합니다. 이러한 흥미로운 특성으로 인해 최근 NeRF를 기반으로 한 연구가 폭발적으로 증가하고 있습니다.
그럼에도 불구하고 실제 애플리케이션에서 런타임 성능은 NeRF의 중요한 한계로 남아 있습니다. 극도의 샘플링 요구 사항과 값비싼 신경망 쿼리로 인해 NeRF 렌더링은 매우 느립니다. 예를 들어, 고성능 GPU를 사용하여 NeRF에서 800x800 이미지를 렌더링하는 데 약 30초가 걸리므로 실시간 인터랙티브 애플리케이션에는 실용적이지 않습니다.
이 작업에서는 NeRF를 계층적 3D 체적 표현으로 추출하여 실시간으로 렌더링하는 방법을 제안합니다. 우리의 접근 방식은 임의의 복잡한 지오메트리와 뷰에 따른 효과를 모든 관점에서 합성할 수 있는 NeRF의 기능을 미리 제공하며 추가적인 감독이 필요하지 않습니다. 실제로 저희의 방법은 많은 경우 기존 NeRF 포뮬레이션의 품질을 능가하는 동시에 상당한 가속을 제공합니다. 이 모델을 사용하면 NVIDIA V100 GPU에서 800x800 이미지를 167.68 FPS로 렌더링할 수 있으며 테스트 시간 동안 심층 신경망에 의존하지 않습니다. 또한, 최신 웹 기술에도 대응할 수 있어 일반 노트북의 브라우저에서 인터랙티브 렌더링이 가능합니다.
나이브 NeRF 렌더링은 모든 샘플에 신경망 추론이 필요한 장면의 고밀도 샘플링이 필요하기 때문에 속도가 느립니다. 이러한 쿼리는 공간적 위치뿐만 아니라 보는 방향에 따라 달라지기 때문에 모든 보는 방향에 대해 이러한 색상 값을 순진하게 캐시할 수 없습니다.
저희는 이러한 문제를 극복하고 실시간 렌더링을 가능하게 하기 위해 Adelsen과 Bergen의 플레놉틱 함수[1]에서 이름을 딴 PlenOcTree 라고 하는 표 형식의 보기 의존적 볼륨으로 NeRF를 사전 샘플링합니다. 특히, 희소 복셀 기반 ocTree를 사용하는데, 이 트리의 모든 리프는 볼륨의 한 지점에서의 광도를 모델링하는 데 필요한 모양과 밀도 값을 저장합니다. 보기에 따라 달라지는 효과를 나타내는 비램버시안 매터리얼을 설명하기 위해 구 표면에 정의된 함수의 표준 기반인 구형 하모닉스(SH)로 한 위치의 RGB 값을 표현할 것을 제안합니다. 구형 하모닉스는 임의의 쿼리 보기 방향에서 평가하여 보기 의존적 색상을 복구할 수 있습니다.
SH 기저 함수에 대한 투영을 통해 기존 NeRF를 이러한 표현으로 변환할 수도 있지만, 우리는 실제로 구형 고조파의 관점에서 명시적으로 모양을 미리 지시하도록 NeRF 네트워크를 수정할 수 있음을 보여줍니다. 특히 원시 RGB 값 대신 SH 함수에 대한 계수를 생성하는 네트워크를 훈련하여 예측된 값을 나중에 PlenOctree의 잎사귀에 직접 저장할 수 있도록 합니다. 또한 NeRF 훈련 중에 스파스퍼리티 프리를 도입하여 옥트리의 메모리 효율을 개선함으로써 결과적으로 더 높은 품질의 이미지를 렌더링할 수 있습니다. 또한 구조가 생성되면 렌더링 프로시저가 차별성을 유지하기 때문에 PlenOctree에 저장된 값을 최적화할 수 있습니다. 이를 통해 PlenOctree는 NeRF와 비교하여 비슷하거나 더 나은 이미지 품질을 얻을 수 있습니다. 우리의 파이프라인은 그림 2에 나와 있습니다.
또한, 저희가 제안한 파이프라인을 사용하여 NeRF 모델 학습을 가속화하는 방법을 보여줌으로써 기존 NeRF 접근 방식보다 더 실용적인 솔루션을 학습할 수 있습니다. 특히, NeRF 모델 학습을 조기에 중단하고 PlenOctree로 변환하면 더 이상 신경망을 사용하지 않기 때문에 훨씬 더 빠르게 학습할 수 있습니다.
실험을 통해 저희의 접근 방식이 이미지 품질 저하 없이 NeRF 기반 렌더링 속도를 5배까지 높일 수 있음을 입증했습니다. 표준 벤치마크에서 우리의 접근 방식을 360도 뷰에서 캡처한 장면과 오브젝트와 비교하고, 이미지 품질과 렌더링 속도에 대한 최첨단 수준의 성능을 보여줍니다.
저희의 인터랙티브 뷰어는 오브젝트 삽입, 복사 분포 시각화, SH 컴포넌트 분해, 장면 분할과 같은 작업을 수행할 수 있습니다. 이러한 실시간 작업이 커뮤니티에서 NeRF 기반 표현을 시각화하고 디버깅하는 데 유용하게 사용될 수 있기를 바랍니다.
요약하자면 저희는 다음과 같은 기여를 하고 있습니다:
- 비슷하거나 향상된 품질로 NeRF를 실시간으로 렌더링하는 첫 번째 방법.
- NeRF-SH: 구형 기저함수의 관점에서 외관을 출력하도록 훈련된 수정된 NeRF.
- PlenOctree: 복잡한 장면을 뷰에 따라 매우 효율적으로 렌더링할 수 있는 NeRF에서 파생된 데이터 구조입니다.
- 조기 훈련 종료를 사용한 가속화된 NeRF 훈련 방법과 PlenOctree 값에 대한 직접 미세 조정 프로세스.

### 2. Related Work
**새로운 뷰 합성.** 사진 세트가 주어지면 장면의 새로운 뷰를 합성하는 작업은 다양한 접근 방식으로 잘 연구된 문제입니다. 모든 방법은 새로운 관점에서 렌더링할 수 있는 기본 기하학적 또는 이미지 기반 3D 표현을 미리 지정합니다. 메시 기반 방법은 표면으로 장면을 표현하며, 램버시안(확산)[56] 및 비램버시안 장면[60, 5, 3]을 모델링하는 데 사용되었습니다.
메시 기반 표현은 컴팩트하고 렌더링하기 쉽지만, 임의의 토폴로지로 구성된 복잡한 장면에 맞게 메시를 최적화하는 것은 어렵습니다. 반면에 이미지 기반 렌더링 방법[19, 43, 60]은 사진처럼 사실적이고 빠르게 렌더링할 수 있지만, 시야각에 제한이 있고 기본 장면을 쉽게 편집할 수 없는 경우가 많습니다.
볼륨 렌더링은 그래픽 커뮤니티에서 오랜 연구 역사를 가진 고전적인 기법입니다[7]. 복셀 그리드[42, 18, 24, 14, 55, 44] 및 다중 평면 이미지(MPI)[49, 35, 64, 48, 29]와 같은 볼륨 기반 표현은 토폴로지가 필요 없는 특성으로 인해 메시 표현의 대안으로 널리 사용되며, 그라데이션 기반 최적화가 간단하고 렌더링이 실시간이 될 수 있습니다. 그러나 이러한 단순한 볼류메트릭 표현은 메모리에 제한이 있어 캡처할 수 있는 최대 해상도가 제한되는 경우가 많습니다. 볼류메트릭 옥트리는 이러한 경우 메모리와 컴퓨팅을 줄이기 위해 널리 사용되는 접근 방식입니다. 옥트리 볼륨 렌더링에 대한 역사적 관점은 이 설문조사[17]를 참조하시기 바랍니다. 옥트리는 최근 다른 3D 작업의 훈련 시 메모리 요구량을 줄이기 위해 사용되었습니다 [39, 11, 52, 57]. 이 작업과 동시에 NeX[59]는 실시간으로 뷰에 따른 렌더링 효과를 가능하게 하는 구형 기저 함수를 인코딩하도록 MPI를 확장했습니다. 이와 동시에 Lombardi 등[25]은 기하학적 프리미티브를 사용하여 데이터를 모델링할 것을 제안하고, [13, 9, 38]은 실시간 렌더링을 가능하게 하는 NeRF를 추출하기도 합니다.
좌표 기반 신경망. 최근 좌표 기반 신경망은 고정된 복셀 표현에 국한되지 않기 때문에 명시적인 체적 표현의 대안으로 각광받고 있습니다. 이러한 방법은 입력은 좌표이고 출력은 해당 위치에 해당하는 공간의 일부 속성인 다층 퍼셉트론(MLP)을 훈련합니다. 이러한 네트워크는 점유[28, 4, 34, 40, 31, 20], 부호화된 거리 필드[32, 10, 61, 62], 방사[30]를 예측하는 데 사용되었습니다. 좌표 기반 신경망은 장면 표현 네트워크[45], NeRF[30], 그리고 많은 NeRF 확장[27, 33, 41, 47]에서 뷰 합성에 사용되었습니다. 이러한 네트워크는 메모리 공간을 늘리지 않고도 임의로 미세한 해상도에서 샘플링할 수 있는 연속 함수를 나타냅니다. 안타깝게도 이러한 소형화는 각 샘플을 신경망으로 처리해야 하기 때문에 계산 효율성이 떨어집니다. 그 결과, 이러한 표현은 종종 느리고 실시간 렌더링에 비실용적입니다.
NeRF 가속. NeRF는 고품질의 결과를 생성할 수 있지만, 렌더링 비용이 많이 들기 때문에 훈련과 추론 속도가 느려집니다. 새로운 장면에 NeRF를 맞추는 프로세스의 속도를 높이는 한 가지 방법은 유사한 장면의 데이터 세트에서 학습한 사전값을 보간하는 것입니다. 이는 예측된 이미지 기능[53, 63, 58] 또는 메타 학습[51]에 대한 컨디셔닝을 통해 달성할 수 있습니다. 추론 속도를 향상시키기 위해 신경 스파스 복셀 필드(NSVF)[23]는 NeRF와 같은 모델에 입력되는 특징의 스파스 복셀 그리드를 학습합니다. 스파스 복셀 그리드를 사용하면 렌더러가 광선을 추적할 때 빈 영역을 건너뛸 수 있으므로 렌더링 시간이 약 10배 향상됩니다. 디컴포지디드 래디언스 필드[37]는 씬을 여러 개의 작은 네트워크로 분해합니다. AutoInt [22]는 추론에 더 적은 수의 샘플이 필요하지만 품질이 낮은 결과를 생성하도록 NeRF의 아키텍처를 수정합니다. 이러한 접근 방식 중 어느 것도 실시간을 달성하지 못합니다. 동시 작업인 DoNeRF는 샘플링의 효율성을 획기적으로 개선하기 위해 NeRF에 깊이 분류기를 추가하지만, 훈련을 위해 실측 깊이가 필요합니다. NeRF를 기반으로 하지는 않지만, 최근 Takikawa 등[50]은 옥트리를 사용하여 신경 SDF 렌더링을 가속화하는 방법을 제안했습니다. 이 작업은 외형 속성을 모델링하지 않는다는 점에 유의하세요. 이와는 대조적으로, 우리는 더 높은 프레임 속도를 달성하면서 사실적인 뷰 의존적 외관을 캡처할 수 있는 체적 표현을 사용합니다.

### 3. Preliminaries
##### 3.1 Neural Radiance Fields
신경 방사 필드(NeRF)[30]는 임의의 새로운 시점에서 렌더링할 수 있는 3D 표현으로, 연속적인 지오메트리와 뷰에 따라 달라지는 외관을 캡처할 수 있습니다. 복사 필드는 보기 방향 d = (θ,φ)에서 위치 x = (x,y,z)에서 쿼리할 수 있는 다층 퍼셉트론(MLP)의 가중치로 인코딩되어 해당 밀도 σ와 색상 c = (r,g,b)를 복구합니다. 픽셀의 예상 색상 C(r)은 광선 r을 볼륨에 투사하고 광선을 따라 밀도를 기준으로 색상을 누적하여 계산합니다. NeRF는 볼륨 렌더링을 수행하기 위해 광선을 따라 N개의 포인트 샘플을 채취하여 누적된 색상을 추정합니다:
![[Pasted image 20231228093846.png]]
여기서 δi는 포인트 샘플 사이의 거리입니다. NeRF 네트워크를 훈련하기 위해 훈련 이미지의 픽셀에 해당하는 광선 R 배치에 대한 예측된 색상 Cˆ은 목표 픽셀 색상과 일치하도록 Adam [15]을 사용하여 최적화됩니다:
![[Pasted image 20231228093912.png]]
장면의 고주파 디테일을 더 잘 표현하기 위해 입력은 위치 인코딩되고 두 단계의 샘플링이 수행됩니다(하나는 거칠고 하나는 미세). 자세한 내용은 NeRF 논문[30]을 참고하시기 바랍니다.

한계. 이 구조의 주목할 만한 결과 중 하나는 광선을 따라 각 샘플을 MLP에 공급하여 해당 σi와 ci를 얻어야 한다는 것입니다. NeRF에 제시된 예시에서는 각 광선에 대해 총 192개의 샘플을 채취했습니다. 대부분의 샘플이 통합된 색상에 기여하지 않는 자유 공간을 샘플링하기 때문에 이는 비효율적입니다. 하나의 대상 이미지를 800×800 해상도로 렌더링하려면 1억 개 이상의 입력으로 네트워크를 실행해야 합니다. 따라서 NVIDIA V100 GPU를 사용하여 단일 프레임을 렌더링하는 데 약 30초가 소요되므로 실시간 애플리케이션에는 비현실적입니다. 저희는 스파스 복셀 옥트리를 사용하여 콘텐츠가 없는 영역에서 과도한 컴퓨팅을 방지합니다. 또한 각 복셀의 값을 미리 계산하여 추론 중에 네트워크 쿼리가 수행되지 않도록 합니다.

### 4. Method
저희는 NeRF를 실시간으로 렌더링할 수 있는 파이프라인을 제안합니다. 훈련된 NeRF가 주어지면 장면에서 비램버시안 효과를 재현할 수 있는 효율적인 데이터 구조인 PlenOctree로 변환할 수 있습니다. 구체적으로는 잎사귀에 구형 고조파(SH) 계수를 저장하는 옥트리로, 뷰에 따라 달라지는 광도를 인코딩합니다.
PlenOctree로의 변환을 보다 간단하게 하기 위해 저희는 SH 계수를 직접 출력하는 NeRF 네트워크의 변형인 NeRF-SH를 제안하여 네트워크에 뷰 방향 입력이 필요하지 않도록 했습니다. 이렇게 변경하면 균일한 그리드에서 평가한 다음 임계값을 설정하여 변환을 수행할 수 있습니다. 이미지 품질을 더욱 향상시키기 위해 훈련 이미지의 옥트리를 미세 조정합니다. 파이프라인의 그래픽 일루젼은 그림 2를 참조하세요.
변환 프로세스는 NeRF의 연속적인 특성을 활용하여 옥트리의 공간 구조를 동적으로 얻습니다. 부분적으로 훈련된 NeRF를 사용하더라도 PlenOctree가 완전히 훈련된 NeRF와 경쟁할 수 있는 결과를 생성할 수 있음을 보여줍니다.
##### 4.1. NeRF-SH: 구형 고조파를 갖는 NeRF
SH는 구형 함수에 대한 저차원 표현으로 널리 사용되어 왔으며, 람-베르티안 표면[36, 2] 또는 광택 표면[46]을 모델링하는 데 사용되었습니다. 여기서는 체적 컨텍스트에서의 사용을 살펴보겠습니다. 특히 RGB 값이 아닌 구형 고조파 계수 k를 출력하도록 NeRF 네트워크 f를 조정합니다.
![[Pasted image 20231228094033.png]]
각 $k_l^m ∈ R^3$은 RGB 구성 요소에 해당하는 3개의 계수 집합입니다. 이 설정에서는 원하는 시야각 d에서 SH 함수 $Y_l^m : S^2 → R$을 쿼리하여 점 x에서 시야에 따라 달라지는 색상 c를 결정할 수 있습니다:
![[Pasted image 20231228094058.png]]
여기서 $S : x → (1 + exp(-x))^{-1}$은 색상을 정규화하기 위한 시그모이드 함수입니다. 즉, 뷰에 따라 달라지는 외관을 SH 기준으로 인수분해하여 네트워크에 대한 뷰 방향 입력을 없애고 변환 시 뷰 방향을 샘플링할 필요성을 제거합니다. SH에 대한 자세한 기술 설명은 부록을 참조하세요. 이제 네트워크에 대한 단일 평가로 인퍼런싱 시간에 임의의 시야각에서 색상을 효율적으로 쿼리할 수 있습니다. 그림 7에서 NeRF-SH의 훈련 속도가 NeRF와 비슷하지만 약간 더 빠르다는 것을 알 수 있습니다(약 10% 정도).
무작위 방향으로 NeRF를 샘플링하고 SH 구성 요소 값을 곱하여 내부 곱의 몬테카를로 추정치를 형성함으로써 각 지점에서 직접 훈련된 NeRF를 SH에 투영할 수도 있습니다. 그러나 이 샘플링 프로세스는 적절한 품질을 달성하는 데 몇 시간이 걸리고 약 2dB의 품질 손실이 발생합니다.1 그럼에도 불구하고 이 대안적인 접근 방식은 기존 NeRF를 PlenOctrees로 변환할 수 있는 경로를 제공합니다.
SH 외에도 모든 주파수 조명을 표현하는 데 사용되어 온 학습 가능한 구형 기반인 구형 가우시안(SG)[8]도 실험하고 있습니다[54, 46, 21]. 저희의 사용 사례에서 SH가 더 나은 성능을 보인다는 사실을 발견했으며, 부록에서 이를 확인할 수 있습니다.

희소성 선행. 정규화 없이 모델은 관찰되지 않은 영역에서 임의의 지오메트리를 자유롭게 생성할 수 있습니다. 이는 이미지 품질을 직접적으로 악화시키지는 않지만, 추가 지오메트리가 상당한 복셀 공간을 차지하기 때문에 변환 프로세스에 악영향을 미칩니다.
이 문제를 해결하기 위해 NeRF 훈련 중에 추가 스파시티 프리를 도입했습니다. 직관적으로, 이 선행 조건은 공간과 단색이 모두 가능한 솔루션일 때 NeRF가 빈 공간을 선택하도록 유도합니다. 공식적으로,
![[Pasted image 20231228094716.png]]
여기서 $\{ σ_k \}^K_{k=1}$은 경계 상자 내의 균일하게 무작위인 K개 지점에서 평가된 밀도 값이며, λ은 하이퍼파라미터입니다. 그러면 최종 훈련 손실은 β스파라시티 L스파라시티 + LRGB이며, 여기서 β스파라시티는 하이퍼파라미터입니다. 그림 3은 이전의 효과를 보여줍니다.
##### 4.2. PlenOctree: 옥트리 기반 래디언스 필드
NeRF-SH 모델을 훈련한 후에는 실시간 렌더링을 위해 이를 스파스 옥트리 표현으로 변환할 수 있습니다. PlenOctree는 각 잎에서 뷰에 따라 달라지는 모양을 모델링하는 밀도와 SH 계수를 저장합니다. 아래에서 변환 및 렌더링 프로세스를 설명합니다.
렌더링. PlenOctree를 렌더링하려면 먼저 각 광선에 대해 옥트리 구조에서 광선-복셀 교차를 결정합니다. 이렇게 하면 복셀 경계 사이에 일정한 밀도와 색상을 가진 길이 {δi}Ni=1의 세그먼트 시퀀스가 생성됩니다. 그런 다음 NeRF의 볼륨 렌더링 모델(1)을 적용하여 광선에 색을 할당합니다. 이 접근 방식을 사용하면 큰 복셀을 한 번에 건너뛰면서 작은 복셀도 놓치지 않을 수 있습니다.
테스트 시 광선의 누적 투과율 Ti가 γ = 0.01 미만일 때 조기 중지를 적용하여 이 렌더링 프로세스를 더욱 가속화합니다.
NeRF-SH에서 변환. 변환 프로세스는 세 단계로 나눌 수 있습니다. 높은 수준에서는 그리드에서 네트워크를 평가하여 밀도 값만 유지한 다음 임계값을 통해 복셀을 필터링합니다. 마지막으로 남은 각 복셀 내의 런덤 포인트를 샘플링하고 평균을 내어 옥트리 잎에 저장할 SH 계수를 얻습니다. 자세한 내용은 아래에 나와 있습니다:
평가. 먼저 균일한 간격의 3D 그리드에서 σ 값을 얻기 위해 NeRF-SH 모델을 평가합니다. 그리드는 장면 콘텐츠에 꼭 맞도록 자동으로 크기가 조정됩니다.2

필터링. 다음으로, 이 그리드를 필터링하여 씬을 표현하기에 충분한 그리드 포인트를 중심으로 한 희소 복셀 세트를 얻습니다. 구체적으로, 이 복셀 그리드를 사용하여 모든 훈련 뷰에 대해 알파 맵을 렌더링하고 각 복셀의 최대 광선 가중치 1 - exp(-σiδi)를 추적합니다. 그런 다음 가중치가 임계값 τw보다 낮은 복셀을 제거합니다. 옥트리는 다시 남는 복셀을 가장 깊은 레벨의 잎으로 포함하고 다른 곳은 비워두도록 구성됩니다. 각 지점에서 σ로 임계값을 설정하는 것과 비교하여 이 방법은 보이지 않는 복셀을 제거합니다.

샘플링. 마지막으로 남은 각 복셀에서 256개의 임의의 점 세트를 샘플링하고 옥트리의 관련 잎을 이 값의 평균으로 설정하여 에일리어싱을 줄입니다. 이제 각 리프에는 각 RGB 컬러 채널에 대한 밀도 σ와 구형 고조파 계수 벡터가 포함됩니다.
이 전체 추출 프로세스는 약 15분 정도 소요됩니다.
##### 4.3. 플렌옥트리 최적화
이 볼륨 렌더링 프로세스는 트리 값에 따라 완전히 달라질 수 있으므로 이미지 품질을 개선하기 위해 SGD로 NeRF 손실(3)을 사용하여 원본 훈련 이미지의 결과 옥트리를 직접 미세 조정할 수 있습니다. 이 과정에서 트리 구조는 NeRF에서 얻은 트리 구조로 고정된다는 점에 유의하세요. PlenOctree 최적화는 초당 약 300만 광선으로 작동하는 반면, NeRF 훈련의 경우 약 9000 광선으로 작동하므로 비교적 짧은 시간에 많은 에포크에 대해 최적화할 수 있습니다. 이 프로세스를 위한 분석 도출은 커스텀 CUDA 커널에서 구현됩니다. 기술적인 세부 사항은 부록으로 넘깁니다.
그림 7에서 볼 수 있듯이, 빠른 옥트리 최적화를 통해 간접적으로 NeRF 트레이닝을 가속화할 수 있는데, 이는 약간의 품질 저하만으로 PlenOctree를 구축하기 위해 더 이른 시점에 NeRF-SH 트레이닝을 중단할 수 있기 때문입니다.

### 5. 결과
##### 5.1. 실험 설정
데이터 세트. 실험에서는 NeRF- 합성 [30] 데이터 세트와 탱크 및 템플 데이터 세트의 하위 집합 [16]을 사용합니다. NeRF 합성 데이터 세트는 8개의 장면으로 구성되며, 각 장면에는 중앙 물체가 있고 100개의 안쪽을 향한 카메라가 상반구에 무작위로 분포되어 있습니다. 이미지는 800×800 크기로 실측 카메라 포즈가 제공됩니다. 탱크와 사원 서브 세트는 NSVF [23]에서 가져온 것으로, 안쪽을 향하는 카메라가 씬을 돌며 캡처한 실제 오브젝트 5개 장면이 포함되어 있습니다. NSVF 제작자가 제공한 포그라운드 마스크를 사용합니다. 각 장면에는 1920 × 1080 크기의 이미지 152~384개가 포함됩니다.
베이스라인. 저희 실험의 주요 기준은 NeRF[30]입니다. 저희는 NeRF(원본)로 표시된 원래의 NeRF 구현과 NeRF-SH 코드의 기반이 되는 Jax[6]의 재구현에 대한 결과를 모두 보고합니다. 달리 명시되지 않는 한, 모든 NeRF 결과와 타이밍은 후자의 구현에서 나온 것입니다. 또한 NeRF 가속을 소개하는 두 개의 최근 논문인 신경 스파스 복셀 필드(NSVF) [23] 및 AutoInt [22]와 두 개의 오래된 방법인 장면 재현 네트워크(SRN) [45] 및 신경 볼륨 [24]과도 비교합니다.
##### 5.2. 품질 평가
위에서 언급한 동기화 및 실제 데이터 세트에 대한 선행 연구와 비교하여 우리의 접근 방식을 평가했습니다. 결과는 각각 표 1과 표 2에 나와 있습니다. 어떤 기준선도 실시간 성능을 달성하지 못하지만, 그럼에도 불구하고 우리의 품질 결과는 모든 경우에서 경쟁력이 있으며 일부 지표에서는 더 우수합니다.
그림 4와 6에서는 PlenOctree 변환이 NeRF에 비해 렌더링된 이미지를 전반적으로 악화시키지 않으며, 오히려 PlenOctree 최적화 프로세스가 텍스트와 같은 미세한 디테일을 향상시킨다는 것을 보여주는 질적 사례를 보여줍니다. 또한 구형 함수 계수를 예측하기 위해 NeRF를 수정해도(NeRF-SH) 성능이 크게 달라지지 않는다는 사실도 확인할 수 있었습니다.
SH의 경우, 합성 데이터 세트와 탱크 및 사원 데이터 세트에서 각각 lmax = 3(16개 컴포넌트) 및 4(25개 컴포넌트)로 설정했습니다. 두 경우 모두 5123 그리드 크기를 사용합니다. 훈련에 대한 자세한 내용은 부록을 다시 참조하세요. 추론 시간 성능은 모든 방법에 대해 Tesla V100에서 측정되었습니다. 두 데이터 세트 모두에서 PlenOctree 추론이 NeRF보다 3000배 이상 빠르며, 다른 모든 비교 방법보다 최소 30배 이상 빠르다는 것을 알 수 있습니다. 모든 이미지 품질 메트릭에서 PlenOctree가 최고 또는 두 번째로 우수한 성능을 보였습니다.
##### 5.3. 속도 트레이드 오프 분석
속도와 이미지 품질 간의 균형을 맞추기 위해 PlenOctree 변환 및 렌더링의 여러 파라미터를 조정할 수 있습니다. 그림 5와 표 3에서는 이러한 트레이드오프에 해당하는 네 가지 PlenOctree 변형에 대한 이미지 정확도와 추론 시간을 비교했습니다. 

##### 5.4. NeRF 훈련의 간접 가속화
4.3절에서 간략히 설명한 것처럼 원본 훈련 데이터에서 옥트리를 효율적으로 미세 조정할 수 있기 때문에 PlenOctree로 변환하기 전에 NeRF-SH 훈련을 더 이른 시점에 중단할 수 있습니다. 실제로 미세 조정 중에 얻은 이미지 품질 개선 효과가 같은 시간 동안 NeRF-SH를 계속 훈련하는 것보다 더 클 수 있다는 사실을 발견했습니다. 따라서 검증이 완료되기 전에 NeRF-SH 트레이닝을 중단하고 플렌옥트리 변환 및 미세 튜닝으로 전환하는 것이 시간적으로 더 효율적일 수 있습니다.
그림 7에서는 각각 2백만 번의 반복 훈련으로 학습된 NeRF 및 NeRF-SH 모델을 NeRF-SH 체크포인트에서 추출한 일련의 PlenOctree 모델과 비교합니다. 시간 제약이 주어지면 거의 항상 NeRF 학습을 중단하고 PlenOctree 최적화로 전환하는 것이 더 바람직하다는 것을 알 수 있습니다.
##### 5.5. 실시간 및 브라우저 내 애플리케이션
인터랙티브 데모. 데스크톱 뷰어에서 PlenOctree 표현에 대해 다양한 실시간 장면 작업을 수행할 수 있습니다. 예를 들어, 적절한 오클루전을 유지하면서 메시를 삽입하거나, PlenOctree를 슬라이스하여 단면을 시각화하거나, 뎁스 맵을 렌더링하여 지오메트리를 확인할 수 있습니다. 다른 기능으로는 공간의 어느 지점에서나 광도 분포를 조사하고 SH 컴포넌트의 하위 집합을 검사할 수 있습니다. 이러한 예는 그림 9에 나와 있습니다. 이러한 작업을 실시간으로 수행할 수 있는 기능은 인터랙티브 엔터테인먼트와 NeRF 관련 애플리케이션 디버깅에 모두 유용합니다.
웹 렌더러. 저희는 브라우저에서 플렌옥트리를 인터랙티브하게 볼 수 있는 웹 기반 렌더러를 구현했습니다. 이는 CUDA 기반 PlenOctree 렌더러를 WebGL 호환 프래그먼트 셰이더로 재작성하고 압축을 적용하여 파일 크기를 줄임으로써 달성할 수 있었습니다. 자세한 내용은 부록을 참조하세요.
### 6. Discussion
저희는 임의의 오브젝트와 장면을 실시간으로 렌더링할 수 있는 PlenOctrees를 사용하여 NeRF를 위한 새로운 데이터 표현을 도입했습니다. 기존 NeRF 방식보다 렌더링 성능을 3000배 이상 가속화할 수 있을 뿐만 아니라 계층적 데이터 구조 덕분에 NeRF와 동등하거나 더 나은 품질의 이미지를 생성할 수 있습니다. 훈련 시간이 NeRF를 실제로 도입하는 데 있어 또 다른 장애물(완전히 수렴하는 데 1~2일 소요)이 될 수 있는 만큼, PlenOctrees를 통해 NeRF-SH의 효과적인 훈련 시간을 단축할 수 있다는 사실도 입증했습니다. 마지막으로, 저희는 We- bGL 기반의 브라우저 내 뷰어를 구현하여 소비자 노트북에서 NeRF의 실시간 및 6-DOF 렌더링 기능을 시연했습니다. 향후에는 이러한 접근 방식을 통해 임의의 복잡성과 재질을 가진 모든 제품을 실시간으로 6-DOF로 시각화할 수 있는 가상 온라인 스토어를 VR에서 구현할 수 있을 것입니다.
한계와 향후 과제. 저희는 최첨단 렌더링 성능과 프레임 속도를 달성했지만, 옥트리 표현은 기존 NeRF 모델의 압축 표현보다 훨씬 더 크고 메모리 사용량도 더 큽니다. 전체 모델의 평균 비압축 옥트리 크기는 합성 데이터 세트의 경우 1.93GB, 탱크 및 사원 데이터 세트의 경우 3.53GB입니다. 온라인 제공의 경우 약 30~120MB의 저해상도 압축 모델을 사용하며, 자세한 내용은 부록을 참조하세요. 이미 어떤 형태로든 가능하지만(그림 8), 우리의 방법을 무한한 장면과 정면을 바라보는 장면에 최적으로 적용하려면 무한한 장면의 데이터 분포가 다르기 때문에 추가 작업이 필요합니다. 정면을 바라보는 장면은 본질적으로 6-DOF 보기를 지원하지 않으며, 이 경우 MPI가 더 적합할 수 있습니다 [59].
향후에는 동적 장면뿐만 아니라 대규모 장면의 실시간 6-DOF 몰입형 시청을 가능하게 하는 방법의 확장을 모색할 계획입니다. 사실적인 3D 콘텐츠를 2D 비디오를 녹화하는 것만큼 쉽게 디지털화할 수 있기 때문에 NeRF의 실시간 렌더링은 차세대 AR/VR 기술의 새로운 표준이 될 수 있다고 믿습니다.